<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Module 4: Difference-in-Differences and Effects of Medicaid Expansion</title>
    <meta charset="utf-8" />
    <meta name="author" content="Ian McCarthy | Emory University" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#E68080"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
    <link rel="stylesheet" href="cols.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Module 4: Difference-in-Differences and Effects of Medicaid Expansion
]
.subtitle[
## Part 3: Understanding Difference-in-Differences
]
.author[
### Ian McCarthy | Emory University
]
.date[
### Econ 470 &amp; HLTH 470
]

---

class: inverse, center, middle


&lt;!-- Adjust some CSS code for font size and maintain R code font size --&gt;
&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code {
  font-size: 15px;
}
.remark-inline-code { 
    font-size: 20px;
}
&lt;/style&gt;


&lt;!-- Set R options for how code chunks are displayed and load packages --&gt;




# The Idea of DD

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# Setup
Want to estimate `\(E[Y_{1}(1)- Y_{0}(1) | D=1]\)`

![:col_header , Post-period, Pre-period]
![:col_row Treated, \(E(Y_{1}(1)|D=1)\), \(E(Y_{0}(0)|D=1)\)]
![:col_row Control, \(E(Y_{0}(1)|D=0)\), \(E(Y_{0}(0)|D=0)\)]

&lt;br&gt;
Problem: We don't see `\(E[Y_{0}(1)|D=1]\)`


---
# Setup
Want to estimate `\(E[Y_{1}(1)- Y_{0}(1) | D=1]\)`

![:col_header , Post-period, Pre-period]
![:col_row Treated, \(E(Y_{1}(1)|D=1)\), \(E(Y_{0}(0)|D=1)\)]
![:col_row Control, \(E(Y_{0}(1)|D=0)\), \(E(Y_{0}(0)|D=0)\)]

&lt;br&gt;
**Strategy 1:** Estimate `\(E[Y_{0}(1)|D=1]\)` using `\(E[Y_{0}(0)|D=1]\)` (before treatment outcome used to estimate post-treatment)


---
# Setup
Want to estimate `\(E[Y_{1}(1)- Y_{0}(1) | D=1]\)`

![:col_header , Post-period, Pre-period]
![:col_row Treated, \(E(Y_{1}(1)|D=1)\), \(E(Y_{0}(0)|D=1)\)]
![:col_row Control, \(E(Y_{0}(1)|D=0)\), \(E(Y_{0}(0)|D=0)\)]

&lt;br&gt;
**Strategy 2:** Estimate `\(E[Y_{0}(1)|D=1]\)` using `\(E[Y_{0}(1)|D=0]\)` (control group used to predict outcome for treatment)


---
# Setup
Want to estimate `\(E[Y_{1}(1)- Y_{0}(1) | D=1]\)`

![:col_header , Post-period, Pre-period]
![:col_row Treated, \(E(Y_{1}(1)|D=1)\), \(E(Y_{0}(0)|D=1)\)]
![:col_row Control, \(E(Y_{0}(1)|D=0)\), \(E(Y_{0}(0)|D=0)\)]

&lt;br&gt;
**Strategy 3:** DD estimate...

Estimate `\(E[Y_{1}(1)|D=1] - E[Y_{0}(1)|D=1]\)` using `\(E[Y_{0}(1)|D=0] - E[Y_{0}(0)|D=0]\)` (pre-post difference in control group used to predict difference for treatment group)

---
# Graphically

&lt;img src="pics/standard-dd.png" width="700px" style="display: block; margin: auto;" /&gt;


---
# Animations

.center[
  ![](pics/dd_animate.gif)
]

---
class: inverse, center, middle
name: estimation

# Average Treatment Effects with DD

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# Estimation
Key identifying assumption is that of *parallel trends*


--
`$$E[Y_{0}(1) - Y_{0}(0)|D=1] = E[Y_{0}(1) - Y_{0}(0)|D=0]$$`

---
# Estimation
Sample means:&lt;br&gt;
`$$\begin{align}
E[Y_{1}(1) - Y_{0}(1)|D=1] &amp;=&amp; \left( E[Y(1)|D=1] - E[Y(1)|D=0] \right) \\
 &amp; &amp; - \left( E[Y(0)|D=1] - E[Y(0)|D=0]\right)
\end{align}$$`


---
# Estimation
Regression:&lt;br&gt;
`\(y_{it} = \alpha + \beta D_{i} + \lambda \times Post_{t} + \delta \times D_{i} \times Post_{t} + \varepsilon_{it}\)`

&lt;br&gt;
![:col_header , After, Before, After - Before]
![:col_row Treated, \(\alpha + \beta + \lambda + \delta\), \(\alpha + \beta\), \(\lambda + \delta\)]
![:col_row Control, \(\alpha + \lambda\), \(\alpha\), \(\lambda\)]
![:col_row Treated - Control, \(\beta + \delta\), \(\beta\), \(\delta\)]


---
# Simulated data

```r
N &lt;- 5000
dd.dat &lt;- tibble(
  d = (runif(N, 0, 1)&gt;0.5),
  time_pre = "pre",
  time_post = "post"
)

dd.dat &lt;- pivot_longer(dd.dat, c("time_pre","time_post"), values_to="time") %&gt;%
  select(d, time) %&gt;%
  mutate(t=(time=="post"),
         y.out=1.5+3*d + 1.5*t + 6*d*t + rnorm(N*2,0,1))
```

---
# Mean differences

```r
dd.means &lt;- dd.dat %&gt;% group_by(d, t) %&gt;% summarize(mean_y = mean(y.out))
knitr::kable(dd.means, col.names=c("Treated","Post","Mean"), format="html")
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Treated &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Post &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Mean &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.536235 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.014374 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; FALSE &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.515127 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; TRUE &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.970610 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Mean differences
In this example:
- `\(E[Y(1)|D=1] - E[Y(1)|D=0]\)` is 8.9562357
- `\(E[Y(0)|D=1] - E[Y(0)|D=0]\)` is 2.9788923

&lt;br&gt;
&lt;br&gt;
So the ATT is 5.9773434



---
# Regression estimator

```r
library(modelsummary)
dd.est &lt;- lm(y.out ~ d + t + d*t, data=dd.dat)
modelsummary(dd.est, gof_map=NA, coef_omit='Intercept')
```

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:center;"&gt;  (1) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; dTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.979 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.028) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; tTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.478 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.028) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; dTRUE × tTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 5.977 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.040) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


---
class: inverse, center, middle
name: handson

# Seeing things in action

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# Application
- Try out some real data on Medicaid expansion following the ACA
- **Question:** Did Medicaid expansion reduce uninsurance?

---
# Step 1: Look at the data

.pull-left[
**Stata**&lt;br&gt;

```stata
insheet using "data/acs_medicaid.txt", clear
gen perc_unins=uninsured/adult_pop
keep if expand_year=="2014" | expand_year=="NA"
drop if expand_ever=="NA"
collapse (mean) perc_unins, by(year expand_ever)
graph twoway (connected perc_unins year if expand_ever=="FALSE", color(black) lpattern(solid)) ///
  (connected perc_unins year if expand_ever=="TRUE", color(black) lpattern(dash)), ///
  xline(2013.5) ///
	ytitle("Fraction Uninsured") xtitle("Year") legend(off) text(0.15 2017 "Non-expansion", place(e)) text(0.08 2017 "Expansion", place(e))
```
]

.pull-right[
**R**&lt;br&gt;

```r
library(tidyverse)  
# mcaid.data &lt;- read_tsv("https://raw.githubusercontent.com/imccart/Insurance-Access/master/data/output/acs_medicaid.txt")
mcaid.data &lt;- read_tsv("../data/acs_medicaid.txt")
ins.plot.dat &lt;- mcaid.data %&gt;% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%
  mutate(perc_unins=uninsured/adult_pop) %&gt;%
  group_by(expand_ever, year) %&gt;% summarize(mean=mean(perc_unins))

ins.plot &lt;- ggplot(data=ins.plot.dat, aes(x=year,y=mean,group=expand_ever,linetype=expand_ever)) + 
  geom_line() + geom_point() + theme_bw() +
  geom_vline(xintercept=2013.5, color="red") +
  geom_text(data = ins.plot.dat %&gt;% filter(year == 2016), 
            aes(label = c("Non-expansion","Expansion"),
                x = year + 1,
                y = mean)) +
  guides(linetype="none") +
  labs(
    x="Year",
    y="Fraction Uninsured",
    title="Share of Uninsured over Time"
  )
```
]

---
# Step 1: Look at the data

&lt;img src="04-dd-part1_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---
# Step 2: Estimate effects
Interested in `\(\delta\)` from:
`$$y_{it} = \alpha + \beta \times Post_{t} + \lambda \times Expand_{i} + \delta \times Post_{t} \times Expand_{i} + \varepsilon_{it}$$`

.pull-left[
**Stata**&lt;br&gt;

```stata
insheet using "data/acs_medicaid.txt", clear
gen perc_unins=uninsured/adult_pop
keep if expand_year=="2014" | expand_year=="NA"
drop if expand_ever=="NA"
gen post=(year&gt;=2014)
gen treat=(expand_ever=="TRUE")
gen treat_post=(expand=="TRUE")

reg perc_unins treat post treat_post

**also try didregress
```
]

.pull-right[
**R**&lt;br&gt;

```r
library(tidyverse)
library(modelsummary)
mcaid.data &lt;- read_tsv("../data/acs_medicaid.txt")
reg.dat &lt;- mcaid.data %&gt;% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%
  mutate(perc_unins=uninsured/adult_pop,
         post = (year&gt;=2014), 
         treat=post*expand_ever)

dd.ins.reg &lt;- lm(perc_unins ~ post + expand_ever + post*expand_ever, data=reg.dat)
```
]

---
# Step 2: Estimate effects

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:center;"&gt;  DD (2014) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; postTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.054 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.003) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; expand_everTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.046 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.016) &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; postTRUE × expand_everTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.019 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.007) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Final DD thoughts

- Key identification assumption is **parallel trends**
- Inference: Typically want to cluster at unit-level to allow for correlation over time within units, but problems with small numbers of treated or control groups:
    - Conley-Taber CIs
    - Wild cluster bootstrap
    - Randomization inference
- "Extra" things like propensity score weighting and doubly robust estimation


---
class: inverse, center, middle
name: twfe

# DD and TWFE

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# What is TWFE?

- Just a shorthand for a common regression specification
- Fixed effects for each unit and each time period, `\(\gamma_{i}\)` and `\(\gamma_{t}\)`
- More general than 2x2 DD but same result

---
# What is TWFE?

Want to estimate `\(\delta\)`:

`$$y_{it} = \alpha + \delta D_{it} + \gamma_{i} + \gamma_{t} + \varepsilon_{it},$$`&lt;br&gt;

where `\(\gamma_{i}\)` and `\(\gamma_{t}\)` denote a set of unit `\(i\)` and time period `\(t\)` dummy variables (or fixed effects).

---
# TWFE in Practice

**2x2 DD**

```r
library(tidyverse)
library(modelsummary)
mcaid.data &lt;- read_tsv("../data/acs_medicaid.txt")
reg.dat &lt;- mcaid.data %&gt;% filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%
  mutate(perc_unins=uninsured/adult_pop,
         post = (year&gt;=2014), 
         treat=post*expand_ever)
m.dd &lt;- lm(perc_unins ~ post + expand_ever + treat, data=reg.dat)
```

**TWFE**

```r
library(fixest)
m.twfe &lt;- feols(perc_unins ~ treat | State + year, data=reg.dat)
```


---
# TWFE in Practice

&lt;table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; DD &lt;/th&gt;
   &lt;th style="text-align:center;"&gt; TWFE &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; postTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.054 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.003) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; expand_everTRUE &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.046 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.016) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; treat &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.019 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; −0.019 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.007) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; (0.007) &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


---
class: inverse, center, middle
name: event

# Event Studies

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# What is an event study?

Event study is poorly named:
- In finance, even study is just an *interrupted time series*
- In econ and other areas, we usually have a treatment/control group *and* a break in time

---
# What is an event study?

- Allows for heterogeneous effects over time (maybe effects phase in over time or dissipate)
- Visually very appealing
- Offers easy evidence against or consistent with parallel trends assumption


---
# What is an event study?

Estimate something akin to...
`$$y_{it} = \gamma_{i} + \gamma_{t} + \sum_{\tau = -q}^{-2}\delta_{\tau} D_{i \tau} + \sum_{\tau=0}^{m} \delta_{\tau}D_{i \tau} + \beta x_{it} + \epsilon_{it},$$`

where `\(q\)` captures the number of periods before the treatment occurs and `\(m\)` captures periods after treatment occurs.

---
# How to do an event study?

1. Create all treatment/year interactions
2. Regressions with full set of interactions and group/year FEs
3. Plot coefficients and standard errors


---
# Things to address

1. "Event time" vs calendar time
2. Define baseline period
3. Choose number of pre-treatment and post-treatment coefficients


---
# Event time vs calendar time

Essentially two "flavors" of event studies

1. Common treatment timing
2. Differential treatment timing

---
# Define baseline period

- Must choose an "excluded" time period (as in all cases of group dummy variables)
- Common choice is `\(t=-1\)` (period just before treatment)
- Easy to understand with calendar time
- For event time...manually set time to `\(t=-1\)` for all untreated units

---
# Number of pre-treatment and post-treatment periods

- On event time, sometimes very few observations for large lead or lag values
- Medicaid expansion example: Late adopting states have fewer post-treatment periods
- Norm is to group final lead/lag periods together


---
# Commont treatment timing

.pull-left[
**Stata**&lt;br&gt;

```stata
ssc install reghdfe

insheet using "data/acs_medicaid.txt", clear
gen perc_unins=uninsured/adult_pop
keep if expand_year=="2014" | expand_year=="NA"
drop if expand_ever=="NA"
gen post=(year&gt;=2014)
gen treat=(expand_ever=="TRUE")
gen treat_post=(expand=="TRUE")

reghdfe perc_unins treat##ib2013.year, absorb(state)
gen coef = .
gen se = .
forvalues i = 2012(1)2018 {
    replace coef = _b[1.treat#`i'.year] if year == `i'
    replace se = _se[1.treat#`i'.year] if year == `i'
}

* Make confidence intervals
gen ci_top = coef+1.96*se
gen ci_bottom = coef - 1.96*se

* Limit ourselves to one observation per year
keep year coef se ci_*
duplicates drop

* Create connected scatterplot of coefficients
* with CIs included with rcap 
* and a line at 0 from function
twoway (sc coef year, connect(line)) (rcap ci_top ci_bottom year) ///
    (function y = 0, range(2012 2018)), xtitle("Year") ///
    caption("Estimates and 95% CI from Event Study")
```
]


.pull-right[
**R**&lt;br&gt;

```r
library(tidyverse)
library(modelsummary)
library(fixest)
mcaid.data &lt;- read_tsv("../data/acs_medicaid.txt")
reg.dat &lt;- mcaid.data %&gt;% 
  filter(expand_year==2014 | is.na(expand_year), !is.na(expand_ever)) %&gt;%
  mutate(perc_unins=uninsured/adult_pop,
         post = (year&gt;=2014), 
         treat=post*expand_ever)

mod.twfe &lt;- feols(perc_unins~i(year, expand_ever, ref=2013) | State + year,
                  cluster=~State,
                  data=reg.dat)
```
]

---
# Common treatment timing

&lt;img src="04-dd-part1_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;



---
# Differential treatment timing

- Now let's work with the full Medicaid expansion data
- Includes late adopters
- Requires putting observations on "event time"

---
# Differential treatment timing

.pull-left[
**Stata**&lt;br&gt;

```stata
ssc install reghdfe

insheet using "data/acs_medicaid.txt", clear
gen perc_unins=uninsured/adult_pop
drop if expand_ever=="NA"
replace expand_year="." if expand_year=="NA"
destring expand_year, replace
gen event_time=year-expand_year
replace event_time=-1 if event_time==.

forvalues l = 0/4 {
	gen L`l'event = (event_time==`l')
}
forvalues l = 1/2 {
	gen F`l'event = (event_time==-`l')
}
gen F3event=(event_time&lt;=-3)

reghdfe perc_unins F3event F2event L0event L1event L2event L3event L4event, absorb(state year) cluster(state)
gen coef = .
gen se = .
forvalues i = 2(1)3 {
    replace coef = _b[F`i'event] if F`i'event==1
    replace se = _se[F`i'event] if F`i'event==1
}
forvalues i = 0(1)4 {
    replace coef = _b[L`i'event] if L`i'event==1
    replace se = _se[L`i'event] if L`i'event==1
}
replace coef = 0 if F1event==1
replace se=0 if F1event==1

* Make confidence intervals
gen ci_top = coef+1.96*se
gen ci_bottom = coef - 1.96*se

* Limit ourselves to one observation per year
keep if event_time&gt;=-3 &amp; event_time&lt;=4
keep event_time coef se ci_*
duplicates drop

* Create connected scatterplot of coefficients
* with CIs included with rcap 
* and a line at 0 from function
sort event_time
twoway (sc coef event_time, connect(line)) (rcap ci_top ci_bottom event_time) ///
    (function y = 0, range(-3 4)), xtitle("Time") ///
    caption("Estimates and 95% CI from Event Study") xlabel(-3(1)4)
```
]

.pull-right[
**R**&lt;br&gt;

```r
library(tidyverse)
library(modelsummary)
library(fixest)
mcaid.data &lt;- read_tsv("../data/acs_medicaid.txt")
reg.dat &lt;- mcaid.data %&gt;% 
  filter(!is.na(expand_ever)) %&gt;%
  mutate(perc_unins=uninsured/adult_pop,
         post = (year&gt;=2014), 
         treat=post*expand_ever,
         time_to_treat = ifelse(expand_ever==FALSE, 0, year-expand_year),
         time_to_treat = ifelse(time_to_treat &lt; -3, -3, time_to_treat))

mod.twfe &lt;- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,
                  cluster=~State,
                  data=reg.dat)
```
]

---
# Differential treatment timing
&lt;img src="04-dd-part1_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;

---
class: inverse, center, middle
name: what

# What are we estimating?

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# Problems with TWFE

- Recall goal of estimating ATE or ATT
- TWFE and 2x2 DD identical with homogeneous effects and common treatment timing
- Otherwise...TWFE is biased and inconsistent for ATT

---
# Intuition

- OLS is a weighted average of all 2x2 DD groups
- Weights are function of size of subsamples, size of treatment/control units, and timing of treatment
- Units treated in middle of sample receive larger weights
- Prior-treated units act as controls for late-treated units


--
Just the length of the panel will change the estimate!

---
# Does it really matter?

- Definitely! But how much?
- Large treatment effects for early treated units could reverse the sign of final estimate
- Let's explore this nice Shiny app from Kyle Butts: [Bacon-Decomposition Shiny App](https://hhsievertsen.shinyapps.io/kylebutts_did_eventstudy/).


---
# Note on parallel trends

Parallel trends violated, in general, if:
1. Policy endogeneity (e.g., selection into treatment due to prior outcome)
2. Compositional differences (problematic in repeated cross-sections)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script src="cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
