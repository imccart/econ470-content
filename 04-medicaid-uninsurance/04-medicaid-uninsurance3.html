<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Module 4: Difference-in-Differences and Effects of Medicaid Expansion</title>
    <meta charset="utf-8" />
    <meta name="author" content="Ian McCarthy | Emory University" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#E68080"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link rel="stylesheet" href="custom.css" type="text/css" />
    <link rel="stylesheet" href="cols.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Module 4: Difference-in-Differences and Effects of Medicaid Expansion
## Part 3: Difference-in-Differences in Practice
### Ian McCarthy | Emory University
### Econ 470 &amp; HLTH 470

---


&lt;!-- Adjust some CSS code for font size and maintain R code font size --&gt;
&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code {
  font-size: 15px;
}
.remark-inline-code { 
    font-size: 20px;
}
&lt;/style&gt;


&lt;!-- Set R options for how code chunks are displayed and load packages --&gt;




# Table of contents

1. [What are Panel Data](#panel)
2. [Estimation with Panel Data](#estimation)
3. [DD in Practice](#dd)
4. [Interpreting](#what)




---
class: inverse, center, middle
name: panel

# What are Panel Data?

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# Nature of the Data

- Repeated observations of the same units over time


--
**Notation**
- Unit `\(i=1,...,N\)` over several periods `\(t=1,...,T\)`, which we denote `\(y_{it}\)`
- Treatment status `\(D_{it}\)`
- Regression model, &lt;br&gt;
`\(y_{it} = \delta D_{it} + \alpha_{i} + \epsilon_{it}\)` for `\(t=1,...,T\)` and `\(i=1,...,N\)`

---
# Benefits of Panel Data

- *May* overcome certain forms of omitted variable bias
- Allows for unobserved but time-invariant factor, `\(\alpha_{i}\)`, that affects both treatment and outcomes


--
**Still assumes**
- No time-varying confounders 
- Past outcomes do not directly affect current outcomes
- Past outcomes do not affect treatment (reverse causality)

---
# Some textbook settings

- Unobserved "ability" when studying schooling and wages
- Unobserved "quality" when studying physicians or hospitals

---
class: inverse, center, middle
name: estimation

# Estimating Regressions with Panel Data

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# Regression model

`\(y_{it} = \alpha + \delta D_{it}  + \epsilon_{it}\)` for `\(t=1,...,T\)` and `\(i=1,...,N\)`

---
# Fixed Effects

`\(y_{it} = \alpha_{i} + \delta D_{it} + \epsilon_{it}\)` for `\(t=1,...,T\)` and `\(i=1,...,N\)`


--
- Allows correlation between `\(\alpha_{i}\)` and `\(D_{it}\)`
- Physically estimate `\(\alpha_{i}\)` in some cases via set of dummy variables
- More generally, "remove" `\(\alpha_{i}\)` via:
  - "within" estimator
  - first-difference estimator
  
---
# Within Estimator
`\(y_{it} = \alpha_{i} + \delta D_{it} +  \epsilon_{it}\)` for `\(t=1,...,T\)` and `\(i=1,...,N\)`


--
- Most common approach (default in most statistical software)
- Equivalent to demeaned model,&lt;br&gt;
`\(y_{it} - \bar{y}_{i} = \delta (D_{it} - \bar{D}_{i}) + (\alpha_{i} - \bar{\alpha}_{i}) + (\epsilon_{it} - \bar{\epsilon}_{i})\)`
- `\(\alpha_{i} - \bar{\alpha}_{i} = 0\)` since `\(\alpha_{i}\)` is time-invariant
- Requires *strict exogeneity* assumption (error is uncorrelated with `\(D_{it}\)` for all time periods)

---
# First-difference
`\(y_{it} = \delta D_{it} + \alpha_{i} + \epsilon_{it}\)` for `\(t=1,...,T\)` and `\(i=1,...,N\)`


--
- Instead of subtracting the mean, subtract the prior period values&lt;br&gt;
`\(y_{it} - y_{i,t-1} = \delta(D_{it} - D_{i,t-1}) + (\alpha_{i} - \alpha_{i}) + (\epsilon_{it} - \epsilon_{i,t-1})\)`
- Requires exogeneity of `\(\epsilon_{it}\)` and `\(D_{it}\)` only for time `\(t\)` and `\(t-1\)` (weaker assumption than within estimator)
- Sometimes useful to estimate both FE and FD just as a check


---
# Keep in mind...

- Discussion only applies to linear case or very specific nonlinear models
- Fixed effects can't solve reverse causality
- Fixed effects doesn't address unobserved, time-varying confounders
- Can't estimate effects on time-invariant variables
- May "absorb" a lot of the variation for variables that don't change much over time

---
# Within Estimator (Default)


```r
library(readstata13)
library(fixest)
wagepan &lt;- read.dta13("http://fmwww.bc.edu/ec-p/data/wooldridge/wagepan.dta")
feols(lwage~exper + expersq | nr, data=wagepan)
```

```
## OLS estimation, Dep. Var.: lwage
## Observations: 4,360 
## Fixed-effects: nr: 545
## Standard-errors: Clustered (nr) 
##          Estimate Std. Error t value Pr(&gt;|t|))    
## exper    0.122257   0.010585 11.5500 &lt; 2.2e-16 ***
## expersq -0.004523   0.000688 -6.5742  1.15e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## RMSE: 0.329464     Adj. R2: 0.562461
##                  Within R2: 0.172696
```


---
# Within Estimator (Manually Demean)


```r
library(readstata13)
wagepan &lt;- read.dta13("http://fmwww.bc.edu/ec-p/data/wooldridge/wagepan.dta")
wagepan &lt;- wagepan %&gt;%
  group_by(nr) %&gt;%
  mutate(demean_lwage=lwage - mean(lwage),
         demean_exper=exper - mean(exper),
         demean_expersq=expersq - mean(expersq))
summary(lm(demean_lwage~demean_exper + demean_expersq, data=wagepan))
```

```
## 
## Call:
## lm(formula = demean_lwage ~ demean_exper + demean_expersq, data = wagepan)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.1752 -0.1221  0.0080  0.1567  1.4875 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     6.557e-17  4.991e-03   0.000        1    
## demean_exper    1.223e-01  7.661e-03  15.959  &lt; 2e-16 ***
## demean_expersq -4.523e-03  5.637e-04  -8.024 1.31e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3296 on 4357 degrees of freedom
## Multiple R-squared:  0.1727,	Adjusted R-squared:  0.1723 
## F-statistic: 454.8 on 2 and 4357 DF,  p-value: &lt; 2.2e-16
```


---
# First differencing


```r
library(readstata13)
wagepan &lt;- read.dta13("http://fmwww.bc.edu/ec-p/data/wooldridge/wagepan.dta")
wagepan &lt;- wagepan %&gt;%
  group_by(nr) %&gt;%
  arrange(year) %&gt;%
  mutate(fd_lwage=lwage - lag(lwage),
         fd_exper=exper - lag(exper),
         fd_expersq=expersq - lag(expersq)) %&gt;%
  na.omit()
summary(lm(fd_lwage~0 + fd_exper + fd_expersq, data=wagepan))
```

```
## 
## Call:
## lm(formula = fd_lwage ~ 0 + fd_exper + fd_expersq, data = wagepan)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5866 -0.1454 -0.0131  0.1319  4.8341 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## fd_exper    0.120232   0.019398   6.198 6.32e-10 ***
## fd_expersq -0.004042   0.001383  -2.922   0.0035 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4434 on 3813 degrees of freedom
## Multiple R-squared:  0.02485,	Adjusted R-squared:  0.02434 
## F-statistic: 48.58 on 2 and 3813 DF,  p-value: &lt; 2.2e-16
```



---
class: inverse, center, middle
name: dd

# DD with Medicaid Expansion

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# Key issue
What is the causal effect of Medicaid expansion?
- Clearly affects insurance markets


--

- but Medicaid enrollment partially crowds out private insurance


---
# Research design
- Use pre/post and expansion/non-expansion states to identify effect of Medicaid expansion
- In a regression structure: 
`$$y_{it} = \alpha + \beta \times 1(Post)_{t} + \gamma D_{i} + \delta \times 1(Post)_{t} \times D_{i} + \varepsilon_{it}$$`

---
# Regression results

```r
ins.dat.2014 &lt;- ins.dat %&gt;% mutate(post = (year&gt;=2014), treat=post*expand_ever) %&gt;% filter(is.na(expand_year) | expand_year==2014)
dd.ins.reg &lt;- lm(perc_unins ~ post + expand_ever + post*expand_ever, data=ins.dat.2014)
summary(dd.ins.reg)
```

```
## 
## Call:
## lm(formula = perc_unins ~ post + expand_ever + post * expand_ever, 
##     data = ins.dat.2014)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.115667 -0.027106 -0.006804  0.027765  0.117597 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               0.213965   0.007180  29.799  &lt; 2e-16 ***
## postTRUE                 -0.054068   0.008496  -6.364 7.22e-10 ***
## expand_everTRUE          -0.046326   0.009166  -5.054 7.48e-07 ***
## postTRUE:expand_everTRUE -0.018403   0.010845  -1.697   0.0908 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.04187 on 304 degrees of freedom
##   (7 observations deleted due to missingness)
## Multiple R-squared:  0.4995,	Adjusted R-squared:  0.4946 
## F-statistic: 101.1 on 3 and 304 DF,  p-value: &lt; 2.2e-16
```

---
# Checking pre-trends
First just plot separately by group:

```r
ins.plot.dat &lt;- ins.dat %&gt;% filter(!is.na(expand_ever)) %&gt;%
  group_by(expand_ever, year) %&gt;% summarize(mean=mean(perc_unins))
  
ggplot(data=ins.plot.dat, aes(x=year,y=mean,group=expand_ever,linetype=expand_ever)) + 
  geom_line() + geom_point() + theme_bw() +
  geom_vline(xintercept=2013.5, color="red") +
  geom_text(data = ins.plot.dat %&gt;% filter(year == 2016), 
            aes(label = c("Non-expansion","Expansion"),
                x = year + 1,
                y = mean)) +
  guides(linetype=FALSE) +
  labs(
    x="Year",
    y="Fraction Uninsured",
    title="Share of Uninsured over Time"
  )
```

.plot-callout[
&lt;img src="04-medicaid-uninsurance3_files/figure-html/unins-group-small-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Checking pre-trends

&lt;img src="04-medicaid-uninsurance3_files/figure-html/unins-group-big-1.png" style="display: block; margin: auto;" /&gt;

---
# Some things to consider

1. Unobserved differences across units or time (TWFE)
2. Heterogeneous treatment effects (event study)

---
# What is TWFE?

- Just a shorthand for a common regression specification
- Fixed effects for each unit and each time period, `\(\lambda_{i}\)` and `\(\lambda_{t}\)`
- More general than 2x2 DD but same result

---
# What is TWFE?
Want to estimate `\(\delta\)`:

`$$y_{it} = \alpha + \delta D_{it} + \gamma_{i} + \gamma_{t} + \varepsilon,$$`&lt;br&gt;

where `\(\gamma_{i}\)` and `\(\gamma_{t}\)` denote a set of unit `\(i\)` and time period `\(t\)` dummy variables (or fixed effects).

---
# Fixed Effects?

Recall our original regression specification:&lt;br&gt;
`$$y_{it} = \alpha + \beta \times 1(Post)_{t} + \gamma D_{i} + \delta \times 1(Post)_{t} \times D_{i} + \varepsilon_{it}$$`

&lt;br&gt;
This is a special case of a general fixed effects estimator:&lt;br&gt;
`\(y_{it} = \alpha + \delta \times 1(Post)_{t} \times D_{i} + \gamma_{i} + \gamma_{t} + \varepsilon\)`,&lt;br&gt;
where `\(\gamma_{i}\)` and `\(\gamma_{t}\)` denote a set of coefficients on state (i) and year (t) dummy variables (or fixed effects).


---
# Fixed Effects?
In R, we can estimate the fixed effects specification using the `felm` command (among others), which is part of the `lfe` package. Intuitively, the treatment dummy is now captured by `\(\gamma_{i}\)` and the pre/post dummy is captured by `\(\gamma_{t}\)`.


--

- Small datasets, estimate `\(\gamma_{i}\)` and `\(\gamma_{t}\)` directly
- Large datasets, "fixed effects" estimators will "remove" those variables

---
# Equivalence
DD is just a special case of the fixed effects approach.


.pull-left[

```r
summary(lm(perc_unins ~ post + expand_ever + post*expand_ever, data=ins.dat.2014))
```

```
## 
## Call:
## lm(formula = perc_unins ~ post + expand_ever + post * expand_ever, 
##     data = ins.dat.2014)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.115667 -0.027106 -0.006804  0.027765  0.117597 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)               0.213965   0.007180  29.799  &lt; 2e-16 ***
## postTRUE                 -0.054068   0.008496  -6.364 7.22e-10 ***
## expand_everTRUE          -0.046326   0.009166  -5.054 7.48e-07 ***
## postTRUE:expand_everTRUE -0.018403   0.010845  -1.697   0.0908 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.04187 on 304 degrees of freedom
##   (7 observations deleted due to missingness)
## Multiple R-squared:  0.4995,	Adjusted R-squared:  0.4946 
## F-statistic: 101.1 on 3 and 304 DF,  p-value: &lt; 2.2e-16
```
]

.pull-right[

```r
summary(felm(perc_unins ~ treat | factor(State) + factor(year), data=ins.dat.2014))
```

```
## 
## Call:
##    felm(formula = perc_unins ~ treat | factor(State) + factor(year),      data = ins.dat.2014) 
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.042349 -0.007307 -0.000520  0.007342  0.039814 
## 
## Coefficients:
##        Estimate Std. Error t value Pr(&gt;|t|)    
## treat -0.018403   0.003702  -4.971 1.22e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.01429 on 257 degrees of freedom
##   (7 observations deleted due to missingness)
## Multiple R-squared(full model): 0.9507   Adjusted R-squared: 0.9411 
## Multiple R-squared(proj model): 0.0877   Adjusted R-squared: -0.08979 
## F-statistic(full model):99.11 on 50 and 257 DF, p-value: &lt; 2.2e-16 
## F-statistic(proj model): 24.71 on 1 and 257 DF, p-value: 1.22e-06
```
]


---
# Event study
This is poorly named:
- In finance, even study is just an *interrupted time series*
- In economics, we usually have a treatment/control group *and* a break in time

---
# Event study

- Allows for different effect estimates at each time period (maybe effects phase in over time or dissipate)
- Visually very appealing
- Offers easy visual test for parallel trends assumption

---
# Event study

Estimate something akin to...
`$$y_{it} = \gamma_{i} + \gamma_{t} + \sum_{\tau = -q}^{-1}\delta_{\tau} D_{i \tau} + \sum_{\tau=0}^{m} \delta_{\tau}D_{i \tau} + x_{it} + \epsilon_{it},$$`

where `\(q\)` captures the number of periods before the treatment occurs and `\(m\)` captures periods after treatment occurs.


---
# Event study
First create all of the treatment/year interactions:

```r
event.dat &lt;- ins.dat.2014 %&gt;%
  mutate(expand_2012 = expand_ever*(year==2012),
         expand_2013 = expand_ever*(year==2013),
         expand_2014 = expand_ever*(year==2014),
         expand_2015 = expand_ever*(year==2015),
         expand_2016 = expand_ever*(year==2016),
         expand_2017 = expand_ever*(year==2017),
         expand_2018 = expand_ever*(year==2018))
```

---
# Event study
Second, run regression with full set of interactions and group/year dummies:

```r
event.ins.reg &lt;- lm(perc_unins ~ expand_2012 + expand_2014 + 
                      expand_2015 + expand_2016 + expand_2017 + 
                      expand_2018 + factor(year) + factor(State), data=event.dat)
point.est &lt;- as_tibble(c(event.ins.reg$coefficients[c("expand_2012","expand_2014","expand_2015",
                                            "expand_2016","expand_2017","expand_2018")]),
                       rownames = "term")
ci.est &lt;- as_tibble(confint(event.ins.reg)[c("expand_2012","expand_2014","expand_2015",
                                   "expand_2016","expand_2017","expand_2018"),],
                    rownames = "term")
```

---
# Event study
Third, organize results into a new dataset:

```r
point.est &lt;- point.est %&gt;% rename(estimate = value)
ci.est &lt;- ci.est %&gt;% rename(conf.low = `2.5 %`, conf.high = `97.5 %`)
new.row &lt;- tibble(
  term = "expand_2013",
  estimate = 0,
  conf.low = 0,
  conf.high = 0,
  year = 2013
)

event.plot.dat &lt;- point.est %&gt;%
  left_join(ci.est, by=c("term")) %&gt;%
  mutate(year = c(2012, 2014, 2015, 2016, 2017, 2018)) %&gt;%
  bind_rows(new.row) %&gt;%
  arrange(year)
```

---
# Event study
Finally, plot coefficients and confidence intervals


.plot-callout[
&lt;img src="04-medicaid-uninsurance3_files/figure-html/es-plot-small-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Event study

&lt;img src="04-medicaid-uninsurance3_files/figure-html/es-plot-big-1.png" style="display: block; margin: auto;" /&gt;



---
# Event study considerations

1. "Event time" vs calendar time
2. Define baseline period
3. Choose number of pre-treatment and post-treatment coefficients


---
# Event time vs calendar time

Essentially two "flavors" of event studies

1. Common treatment timing
2. Differential treatment timing

---
# Define baseline period

- Must choose an "excluded" time period (as in all cases of group dummy variables)
- Common choice is `\(t=-1\)` (period just before treatment)
- Easy to understand with calendar time
- For event time...manually set time to `\(t=-1\)` for all untreated units

---
# Number of pre-treatment and post-treatment periods

- On event time, sometimes very few observations for large lead or lag values
- Medicaid expansion example: Late adopting states have fewer post-treatment periods
- Norm is to group final lead/lag periods together

---
# In practice


```r
reg.dat &lt;- ins.dat %&gt;% 
  filter(!is.na(expand_ever)) %&gt;%
  mutate(post = (year&gt;=2014), 
         treat=post*expand_ever,
         time_to_treat = ifelse(expand_ever==FALSE, 0, year-expand_year),
         time_to_treat = ifelse(time_to_treat &lt; -3, -3, time_to_treat))

mod.twfe &lt;- feols(perc_unins~i(time_to_treat, expand_ever, ref=-1) | State + year,
                  cluster=~State,
                  data=reg.dat)
```

---
# In practice


```r
iplot(mod.twfe, 
      xlab = 'Time to treatment',
      main = 'Event study')
```

&lt;img src="04-medicaid-uninsurance3_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;


---
class: inverse, center, middle
name: what

# What are we estimating?

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# Problems with TWFE

- Recall goal of estimating ATE or ATT
- TWFE and 2x2 DD identical with homogeneoues effects and common treatment timing
- Otherwise...TWFE is biased and inconsistent for ATT

---
# Inutition

- OLS is a weighted average of all 2x2 DD groups
- Weights are function of size of subsamples, size of treatment/control units, and timing of treatment
- Units treated in middle of sample receive larger weights
- Prior-treated units act as controls for late-treated units


--
Just the length of the panel will change the estimate!

---
# Does it really matter?

- Definitely! But how much?
- Large treatment effects for early treated units could reverse the sign of final estimate
- Let's explore this nice Shiny app : [Bacon-Decomposition Shiny App](https://hhsievertsen.shinyapps.io/kylebutts_did_eventstudy/).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script src="cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
