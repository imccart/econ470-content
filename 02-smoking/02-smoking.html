<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Section 2: Demand for Cigarettes and Instrumental Variables</title>
    <meta charset="utf-8" />
    <meta name="author" content="Ian McCarthy | Emory University" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#E68080"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Section 2: Demand for Cigarettes and Instrumental Variables
## <html>
<div style="float:left">

</div>
<hr color='#EB811B' size=1px width=0px>
</html>
### Ian McCarthy | Emory University
### Econ 470 &amp; HLTH 470

---


&lt;!-- Adjust some CSS code for font size and maintain R code font size --&gt;
&lt;style type="text/css"&gt;
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code {
  font-size: 15px;
}
.remark-inline-code { 
    font-size: 20px;
}
&lt;/style&gt;


&lt;!-- Set R options for how code chunks are displayed and load packages --&gt;





# Table of contents

1. [Smoking Literature](#smoking_lit)

2. [Cigarette Data](#smoking_data)

3. [Instrumental Variables](#IV)

4. [Estimating Demand for Cigarettes](#smoking_demand)



&lt;!-- New Section --&gt;
---
class: inverse, center, middle
name: smoking_lit

# Background on Cigarettes and Pricing

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# History of Smoking

.center[
  ![:scale 700px](https://media.giphy.com/media/TdQfYM6KpYQUM/giphy.gif)
]

---
# History of Smoking
- Widespread smoking began in late 1800s
- Lung cancer becoming more common after 1930s
- First evidence of link in 1950s
- Surgeon general's report in 1964
- Very important in causal inference! ([Section 5.1.1](https://mixtape.scunning.com/matching-and-subclassification.html#some-background) of Causal Inference Mixtape)

---
# Why it matters
1. Extreme public health concerns
  - Lung cancer prevalence
  - Fetal and baby health
  
2. Economic questions
  - Is it an information problem?
  - Externalities (second-hand smoke)
  - Moral hazard due to insurance
  
---
# In our case
We want to focus on estimating demand for cigarettes. By this, I mean estimating price elasticity of demand.

--
&lt;br&gt;

We'll show that standard OLS isn't going to do this very well.

&lt;!-- New Section --&gt;
---
class: inverse, center, middle
name: smoking_data

# Cigarette Data

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# The Data

- Data from [CDC Tax Burden on Tobacco](https://data.cdc.gov/Policy/The-Tax-Burden-on-Tobacco-1970-2018/7nwe-3aj9/data)

- Visit GitHub repository for other info: [Tobacco GitHub repository](https://github.com/imccart/CDC-Tobacco)

- Supplement with CPI data, also in GitHub repo.

---
# Summary stats
We're interested in cigarette prices and sales, so let's focus our summaries on those two variables

```r
stargazer(as.data.frame(cig.data %&gt;% select(sales_per_capita, price_cpi, cost_per_pack)), type="html")
```


&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="8" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;Statistic&lt;/td&gt;&lt;td&gt;N&lt;/td&gt;&lt;td&gt;Mean&lt;/td&gt;&lt;td&gt;St. Dev.&lt;/td&gt;&lt;td&gt;Min&lt;/td&gt;&lt;td&gt;Pctl(25)&lt;/td&gt;&lt;td&gt;Pctl(75)&lt;/td&gt;&lt;td&gt;Max&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="8" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;sales_per_capita&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;95.150&lt;/td&gt;&lt;td&gt;41.133&lt;/td&gt;&lt;td&gt;12.500&lt;/td&gt;&lt;td&gt;63.050&lt;/td&gt;&lt;td&gt;122.400&lt;/td&gt;&lt;td&gt;296.200&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;price_cpi&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;3.396&lt;/td&gt;&lt;td&gt;1.641&lt;/td&gt;&lt;td&gt;1.307&lt;/td&gt;&lt;td&gt;2.088&lt;/td&gt;&lt;td&gt;4.520&lt;/td&gt;&lt;td&gt;9.651&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;cost_per_pack&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2.678&lt;/td&gt;&lt;td&gt;2.238&lt;/td&gt;&lt;td&gt;0.287&lt;/td&gt;&lt;td&gt;0.780&lt;/td&gt;&lt;td&gt;4.237&lt;/td&gt;&lt;td&gt;10.376&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="8" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;


---
# Cigarette Sales

```r
cig.data %&gt;% 
  ggplot(aes(x=Year,y=sales_per_capita)) + 
  stat_summary(fun.y="mean",geom="line") +
  labs(
    x="Year",
    y="Packs per Capita",
    title="Cigarette Sales"
  ) + theme_bw() +
  scale_x_continuous(breaks=seq(1970, 2020, 5))
```
.plot-callout[
&lt;img src="02-smoking_files/figure-html/cig-sales-callout-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Cigarette Sales

&lt;img src="02-smoking_files/figure-html/cig-sales-output-1.png" style="display: block; margin: auto;" /&gt;

---
# Cigarette Prices

```r
cig.data %&gt;% 
  ggplot(aes(x=Year,y=price_cpi)) + 
  stat_summary(fun.y="mean",geom="line") +
  labs(
    x="Year",
    y="Price per Pack ($)",
    title="Cigarette Prices in 2010 Real Dollars"
  ) + theme_bw() +
  scale_x_continuous(breaks=seq(1970, 2020, 5))
```
.plot-callout[
&lt;img src="02-smoking_files/figure-html/cig-price-callout-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Cigarette Prices

&lt;img src="02-smoking_files/figure-html/cig-price-output-1.png" style="display: block; margin: auto;" /&gt;



&lt;!-- New Section --&gt;
---
class: inverse, center, middle
name: IV

# Instrumental Variables

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;


---
# What is instrumental variables
Instrumental Variables (IV) is a way to identify causal effects using variation in treatment particpation that is due to an *exogenous* variable that is only related to the outcome through treatment.


---
# Why bother with IV?
Two reasons to consider IV:
1. Selection on unobservables
2. Reverse causation

--
&lt;br&gt;

Either problem is sometimes loosely referred to as *endogeneity*

---
# Simple example
- `\(y = \beta x + \varepsilon (x)\)`,&lt;br&gt;
where `\(\varepsilon(x)\)` reflects the dependence between our observed variable and the error term.&lt;br&gt;

- Simple OLS will yield&lt;br&gt;
`\(\frac{dy}{dx} = \beta + \frac{d\varepsilon}{dx} \neq \beta\)`


---
# What does IV do?
- The regression we want to do: &lt;br&gt;
`\(y_{i} = \alpha + \delta D_{i} + \gamma A_{i} + \epsilon_{i}\)`,&lt;br&gt;
where `\(D_{i}\)` is treatment (think of schooling for now) and `\(A_{i}\)` is something like ability.

- `\(A_{i}\)` is unobserved, so instead we run: &lt;br&gt;
`\(y_{i} = \alpha + \beta D_{i} + \epsilon_{i}\)`

- From this "short" regression, we don't actually estimate `\(\delta\)`. Instead, we get an estimate of&lt;br&gt;
`\(\beta = \delta + \lambda_{ds}\gamma \neq \delta\)`,&lt;br&gt;
where `\(\lambda_{ds}\)` is the coefficient of a regression of `\(A_{i}\)` on `\(D_{i}\)`. 

---
# Intuition
IV will recover the "long" regression without observing underlying ability&lt;br&gt;

--
&lt;br&gt;

*IF* our IV satisfies all of the necessary assumptions.

---
# More formally
- We want to estimate&lt;br&gt;
`\(E[Y_{i} | D_{i}=1] - E[Y_{i} | D_{i}=0]\)`

- With instrument `\(Z_{i}\)` that satisfies relevant assumptions, we can estimate this as&lt;br&gt;
`\(E[Y_{i} | D_{i}=1] - E[Y_{i} | D_{i}=0] = \frac{E[Y_{i} | Z_{i}=1] - E[Y_{i} | Z_{i}=0]}{E[D_{i} | Z_{i}=1] - E[D_{i} | Z_{i}=0]}\)`

- In words, this is effect of the instrument on the outcome ("reduced form") divided by the effect of the instrument on treatment ("first stage")

---
# Derivation
Recall "long" regression: `\(Y=\alpha + \delta S + \gamma A + \epsilon\)`.

`$$\begin{align}
COV(Y,Z) &amp; = E[YZ] - E[Y] E[Z] \\
         &amp; = E[(\alpha + \delta S + \gamma A + \epsilon)\times Z] - E[\alpha + \delta S + \gamma A + \epsilon)]E[Z] \\
         &amp; = \alpha E[Z] + \delta E[SZ] + \gamma E[AZ] + E[\epsilon Z] \\
         &amp; \hspace{.2in} - \alpha E[Z] - \delta E[S]E[Z] - \gamma E[A] E[Z] - E[\epsilon]E[Z] \\
         &amp; = \delta (E[SZ] - E[S] E[Z]) + \gamma (E[AZ] - E[A] E[Z]) \\
         &amp; \hspace{.2in} + E[\epsilon Z] - E[\epsilon] E[Z] \\
         &amp; = \delta C(S,Z) + \gamma C(A,Z) + C(\epsilon, Z)
\end{align}$$`

---
# Derivation

Working from `\(COV(Y,Z) = \delta COV(S,Z) + \gamma COV(A,Z) + COV(\epsilon,Z)\)`, we find

`$$\delta = \frac{COV(Y,Z)}{COV(S,Z)}$$`

if `\(COV(A,Z)=COV(\epsilon, Z)=0\)`

---
# IVs in practice
Easy to think of in terms of randomized controlled trial...

--
&lt;br&gt;

 Measure    | Offered Seat | Not Offered Seat | Difference 
 ---------- | ------------ | ---------------- | ---------- 
 Score      | -0.003       | -0.358           | 0.355      
 % Enrolled | 0.787        | 0.046            | 0.741   
 Effect     |              |                  | 0.48

&lt;br&gt;

.footnote[
Angrist *et al.*, 2012. "Who Benefits from KIPP?" *Journal of Policy Analysis and Management*.
] 


---
# What is IV *really* doing
Think of IV as two-steps:

1. Isolate variation due to the instrument only (not due to endogenous stuff)
2. Estimate effect on outcome using only this source of variation

---
# In regression terms
Interested in estimating `\(\delta\)` from `\(y_{i} = \alpha + \beta x_{i} + \delta D_{i} + \varepsilon_{i}\)`, but `\(D_{i}\)` is endogenous (no pure "selection on observables").

--
&lt;br&gt;

&lt;b&gt;Step 1:&lt;/b&gt; With instrument `\(Z_{i}\)`, we can regress `\(D_{i}\)` on `\(Z_{i}\)` and `\(x_{i}\)`,&lt;br&gt;
`\(D_{i} = \lambda + \theta Z_{i} + \kappa x_{i} + \nu\)`,&lt;br&gt;
and form prediction `\(\hat{D}_{i}\)`.

--
&lt;br&gt;

&lt;b&gt;Step 2:&lt;/b&gt; Regress `\(y_{i}\)` on `\(x_{i}\)` and `\(\hat{D}_{i}\)`,&lt;br&gt;
`\(y_{i} = \alpha + \beta x_{i} + \delta \hat{D}_{i} + \xi_{i}\)`


---
# Derivation
Recall `\(\hat{\theta}=\frac{C(Z,S)}{V(Z)}\)`, or `\(\hat{\theta}V(Z) = C(Y,Z)\)`. Then:

`$$\begin{align}
\hat{\delta}  &amp; = \frac{COV(Y,Z)}{COV(S,Z)} \\
        &amp; = \frac{\hat{\theta}C(Y,Z)}{\hat{\theta}C(S,Z)} = \frac{\hat{\theta}C(Y,Z)}{\hat{\theta}^{2}V(Z)} \\
        &amp; = \frac{C(\hat{\theta}Z,Y)}{V(\hat{\theta}Z)} = \frac{C(\hat{S},Y)}{V(\hat{S})}
\end{align}$$`


---
# In regression terms
But in practice, *DON'T* do this in two steps. Why?

--
&lt;br&gt;

Because standard errors are wrong...not accounting for noise in prediction, `\(\hat{D}_{i}\)`. The appropriate fix is built into most modern stats programs.


---
# Key IV assumptions
1. *Exclusion:* Instrument is uncorrelated with the error term&lt;br&gt;

2. *Validity:* Instrument is correlated with the endogenous variable&lt;br&gt;

3. *Monotonicity:* Treatment more (less) likely for those with higher (lower) values of the instrument&lt;br&gt;

--
&lt;br&gt;

Assumptions 1 and 2 sometimes grouped into an *only through* condition.


---
# Animation for IV


.center[
  ![:scale 900px](pics/iv_animate.gif)
]

---
# Simulated data
.pull-left[

```r
n &lt;- 5000
b.true &lt;- 5.25
iv.dat &lt;- tibble(
  z = rnorm(n,0,2),
  eps = rnorm(n,0,1),
  d = (z + 1.5*eps + rnorm(n,0,1) &gt;0.25),
  y = 2.5 + b.true*d + eps + rnorm(n,0,0.5)
)
```
]

.pull-right[
- endogenous `eps`: affects treatment and outcome
- `z` is an instrument: affects treatment but no direct effect on outcome
]

---
# Results with simulated data
Recall that the *true* treatment effect is 5.25
.pull-left[

```
## 
## Call:
## lm(formula = y ~ d, data = iv.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.8475 -0.7007 -0.0197  0.7043  3.8847 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.07350    0.02002   103.6   &lt;2e-16 ***
## dTRUE        6.16139    0.02951   208.8   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.04 on 4998 degrees of freedom
## Multiple R-squared:  0.8971,	Adjusted R-squared:  0.8971 
## F-statistic: 4.359e+04 on 1 and 4998 DF,  p-value: &lt; 2.2e-16
```
]


.pull-right[

```
## 
## Call:
## ivreg(formula = y ~ d | z, data = iv.dat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -4.25908 -0.76874  0.02717  0.74829  4.36714 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.48509    0.02992   83.05   &lt;2e-16 ***
## dTRUE        5.26741    0.05492   95.92   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.132 on 4998 degrees of freedom
## Multiple R-Squared: 0.8783,	Adjusted R-squared: 0.8782 
## Wald test:  9200 on 1 and 4998 DF,  p-value: &lt; 2.2e-16
```
]

---
# Checking instrument
.pull-left[
- Check the 'first stage'

```
## 
## Call:
## lm(formula = d ~ z, data = iv.dat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.18377 -0.33100 -0.02694  0.34211  1.04655 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.457369   0.005720   79.96   &lt;2e-16 ***
## z           0.145662   0.002859   50.95   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4045 on 4998 degrees of freedom
## Multiple R-squared:  0.3418,	Adjusted R-squared:  0.3417 
## F-statistic:  2596 on 1 and 4998 DF,  p-value: &lt; 2.2e-16
```
]

.pull-right[
- Check the 'reduced form'

```
## 
## Call:
## lm(formula = y ~ z, data = iv.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -8.6854 -2.0943 -0.0718  2.0937  9.5522 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.05943    0.03960  127.78   &lt;2e-16 ***
## z            0.86070    0.01975   43.59   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.8 on 4998 degrees of freedom
## Multiple R-squared:  0.2754,	Adjusted R-squared:  0.2753 
## F-statistic:  1900 on 1 and 4998 DF,  p-value: &lt; 2.2e-16
```
]


---
# Two-stage equivalence

```r
step1 &lt;- lm(d ~ z, data=iv.dat)
d.hat &lt;- predict(step1)
step2 &lt;- lm(y ~ d.hat, data=iv.dat)
summary(step2)
```

```
## 
## Call:
## lm(formula = y ~ d.hat, data = iv.dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.0433 -2.2201 -0.1163  2.2259  8.3417 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.48509    0.07554    32.9   &lt;2e-16 ***
## d.hat        5.26741    0.13863    38.0   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.857 on 4998 degrees of freedom
## Multiple R-squared:  0.2241,	Adjusted R-squared:  0.224 
## F-statistic:  1444 on 1 and 4998 DF,  p-value: &lt; 2.2e-16
```


---
# IV Diagnostics


---
# LATE and IV Interpretation


---
# Violation of IV Assumptions



&lt;!-- New Section --&gt;
---
class: inverse, center, middle
name: smoking_demand

# Estimating Demand for Cigarettes

&lt;html&gt;&lt;div style='float:left'&gt;&lt;/div&gt;&lt;hr color='#EB811B' size=1px width=1055px&gt;&lt;/html&gt;

---
# Naive estimate
Clearly a strong relationship between prices and sales. For example, just from OLS:

```
## 
## Call:
## lm(formula = ln_sales ~ ln_price, data = cig.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.23899 -0.17057  0.02239  0.18605  1.13866 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.689838   0.007209  650.55   &lt;2e-16 ***
## ln_price    -0.420307   0.006464  -65.02   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3073 on 2497 degrees of freedom
## Multiple R-squared:  0.6287,	Adjusted R-squared:  0.6285 
## F-statistic:  4228 on 1 and 2497 DF,  p-value: &lt; 2.2e-16
```

---
# Is this causal?
- But is that the true demand curve?

- Aren't other things changing that tend to reduce cigarette sales?

---
# Tax as an IV

```r
cig.data %&gt;% 
  ggplot(aes(x=Year,y=total_tax_cpi)) + 
  stat_summary(fun.y="mean",geom="line") +
  labs(
    x="Year",
    y="Tax per Pack ($)",
    title="Cigarette Taxes in 2010 Real Dollars"
  ) + theme_bw() +
  scale_x_continuous(breaks=seq(1970, 2020, 5))
```

.plot-callout[
&lt;img src="02-smoking_files/figure-html/cig-tax-callout-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Tax as an IV

&lt;img src="02-smoking_files/figure-html/cig-tax-output-1.png" style="display: block; margin: auto;" /&gt;


---
# IV Results


```
## 
## Call:
## ivreg(formula = ln_sales ~ ln_price | total_tax_cpi, data = cig.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.24595 -0.23048  0.02863  0.23548  1.30999 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.805691   0.009703  495.29   &lt;2e-16 ***
## ln_price    -0.619142   0.011128  -55.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3608 on 2497 degrees of freedom
## Multiple R-Squared: 0.488,	Adjusted R-squared: 0.4878 
## Wald test:  3096 on 1 and 2497 DF,  p-value: &lt; 2.2e-16
```

---
# Two-stage equivalence

```r
step1 &lt;- lm(ln_price ~ total_tax_cpi, data=cig.data)
pricehat &lt;- predict(step1)
step2 &lt;- lm(ln_sales ~ pricehat, data=cig.data)
summary(step2)
```

```
## 
## Call:
## lm(formula = ln_sales ~ pricehat, data = cig.data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.10960 -0.17805  0.01867  0.18697  1.14907 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.805691   0.008195  586.41   &lt;2e-16 ***
## pricehat    -0.619142   0.009399  -65.87   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3048 on 2497 degrees of freedom
## Multiple R-squared:  0.6348,	Adjusted R-squared:  0.6346 
## F-statistic:  4339 on 1 and 2497 DF,  p-value: &lt; 2.2e-16
```




---
# Different specifications

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="6"&gt;Log Sales per Capita&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;OLS&lt;/td&gt;&lt;td colspan="3"&gt;IV&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;(1)&lt;/td&gt;&lt;td&gt;(2)&lt;/td&gt;&lt;td&gt;(3)&lt;/td&gt;&lt;td&gt;(4)&lt;/td&gt;&lt;td&gt;(5)&lt;/td&gt;&lt;td&gt;(6)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;Log Price&lt;/td&gt;&lt;td&gt;-0.953&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-0.921&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-1.213&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-1.072&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-1.036&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-1.523&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;(0.012)&lt;/td&gt;&lt;td&gt;(0.008)&lt;/td&gt;&lt;td&gt;(0.034)&lt;/td&gt;&lt;td&gt;(0.014)&lt;/td&gt;&lt;td&gt;(0.010)&lt;/td&gt;&lt;td&gt;(0.041)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;State FE&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Year FE&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Observations&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/td&gt;&lt;td colspan="6" style="text-align:right"&gt;&lt;sup&gt;*&lt;/sup&gt;p&lt;0.1; &lt;sup&gt;**&lt;/sup&gt;p&lt;0.05; &lt;sup&gt;***&lt;/sup&gt;p&lt;0.01&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;


---
# Test the IV

&lt;table style="text-align:center"&gt;&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;Log Price&lt;/td&gt;&lt;td colspan="3"&gt;Log Sales&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td colspan="3"&gt;First Stage&lt;/td&gt;&lt;td colspan="3"&gt;Reduced Form&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;(1)&lt;/td&gt;&lt;td&gt;(2)&lt;/td&gt;&lt;td&gt;(3)&lt;/td&gt;&lt;td&gt;(4)&lt;/td&gt;&lt;td&gt;(5)&lt;/td&gt;&lt;td&gt;(6)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;Tax per Pack&lt;/td&gt;&lt;td&gt;0.444&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;0.474&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;0.187&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-0.476&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-0.491&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;-0.284&lt;sup&gt;***&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;/td&gt;&lt;td&gt;(0.006)&lt;/td&gt;&lt;td&gt;(0.006)&lt;/td&gt;&lt;td&gt;(0.002)&lt;/td&gt;&lt;td&gt;(0.007)&lt;/td&gt;&lt;td&gt;(0.006)&lt;/td&gt;&lt;td&gt;(0.007)&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;State FE&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Year FE&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;No&lt;/td&gt;&lt;td&gt;Yes&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style="text-align:left"&gt;Observations&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;td&gt;2,499&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td colspan="7" style="border-bottom: 1px solid black"&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style="text-align:left"&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/td&gt;&lt;td colspan="6" style="text-align:right"&gt;&lt;sup&gt;*&lt;/sup&gt;p&lt;0.1; &lt;sup&gt;**&lt;/sup&gt;p&lt;0.05; &lt;sup&gt;***&lt;/sup&gt;p&lt;0.01&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

---
# Summary
1. Most elasticities of around -0.25% to -0.37%

2. Much larger elasticities when including year fixed effects

3. Perhaps not too outlandish given more recent evidence: [NBER Working Paper](https://www.nber.org/papers/w22251.pdf).

---
# Some other IV issues

1. IV estimators are biased. Performance in finite samples is questionable.

2. IV estimators provide an estimate of a Local Average Treatment Effect (LATE), which is only the same as the ATT under some conditions or assumptions.

3. What about lots of instruments? The finite sample problem is more important and we may try other things (JIVE).&lt;br&gt;

--
&lt;br&gt;
The National Bureau of Economic Researh (NBER) has a great resource [here](https://www.nber.org/econometrics_minicourse_2018/2018si_methods.pdf) for understanding instruments in practice.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
