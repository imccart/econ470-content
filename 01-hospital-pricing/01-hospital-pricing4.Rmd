---
title: "Module 1: Hospital Pricing and Selection on Observables"
subtitle: "Part 4: Hospital Prices and Penalties"
author: Ian McCarthy | Emory University
date: Econ 470 & HLTH 470 #"`r format(Sys.time(), '%d %B %Y')`"
header-includes: 
  - \usepackage{graphicx}
  - \usepackage{amsmath}
  - \usepackage{mathtools}
output:
#  html_document: default
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts, custom.css] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: "macros.js"
knit: pagedown::chrome_print
---

<!-- Adjust some CSS code for font size and maintain R code font size -->
<style type="text/css">
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code {
  font-size: 15px;
}
.remark-inline-code { 
    font-size: 20px;
}
</style>


<!-- Set R options for how code chunks are displayed and load packages -->
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
knitr::opts_chunk$set(
  fig.align="center",  
  fig.height=3, #fig.width=6,
  # out.width="748px", #out.length="520.75px",
  dpi=300, #fig.path='Figs/',
  cache=T,# echo=F, warning=F, message=F
  warning = FALSE, 
  message = FALSE, 
  cache.lazy = FALSE,
  error=TRUE
  )

knitr::opts_hooks$set(fig.callout = function(options) {
  if(options$fig.callout) {
    options$echo = FALSE
  }
  options
})

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, ggplot2, dplyr, lubridate, readr, readxl, hrbrthemes,
               scales, plotly, gganimate, cobalt, MatchIt, ggthemes, here, latex2exp,
               hettreatreg)
set.seed(12345)
```

```{r xaringan-scribble, echo=FALSE}
xaringanExtra::use_scribble(rgb(0.9, 0.5, 0.5))
```


# Penalized hospitals
```{r final-data}
hcris.data <- read_rds(here("data/HCRIS_Data.rds"))

hcris.data <- hcris.data %>%
  mutate( discount_factor = 1-tot_discounts/tot_charges,
          price_num = (ip_charges + icu_charges + ancillary_charges)*discount_factor - tot_mcare_payment,
          price_denom = tot_discharges - mcare_discharges,
          price = price_num/price_denom)

final.hcris <- hcris.data %>% ungroup() %>%
  filter(price_denom>100, !is.na(price_denom), 
         price_num>0, !is.na(price_num),
         price<100000, 
         beds>30, year==2012) %>%  #<<
  mutate( hvbp_payment = ifelse(is.na(hvbp_payment),0,hvbp_payment),
          hrrp_payment = ifelse(is.na(hrrp_payment),0,abs(hrrp_payment)), #<<
    penalty = (hvbp_payment-hrrp_payment<0)) #<<
```

```{r, include=F}
mean.pen <- round(mean(final.hcris$price[which(final.hcris$penalty==1)]),2)
mean.nopen <- round(mean(final.hcris$price[which(final.hcris$penalty==0)]),2)
```

---
# Summary stats
Always important to look at your data before doing any formal analysis. Ask yourself a few questions:
1. Are the magnitudes reasonable?

2. Are there lots of missing values?

3. Are there clear examples of misreporting?

---
# Summary stats

.pull-left[
```{r}
summary(hcris.data$price)
plot(density(hcris.data$price, na.rm=TRUE))
```
]

.pull-right[
```{r}
summary(final.hcris$price)
plot(density(final.hcris$price))
```
]

---
# Dealing with problems
We've adopted a very brute force way to deal with outlier prices. Other approaches include:
1. Investigate very closely the hospitals with extreme values

2. Winsorize at certain thresholds (replace extreme values with pre-determined thresholds)

3. Impute prices for extreme hospitals

---
# Differences among penalized hospitals
- Mean price among penalized hospitals: `r format(mean.pen, big.mark=",")`
- Mean price among non-penalized hospitals: `r format(mean.nopen, big.mark=",")`
- Mean difference: `r format(mean.pen-mean.nopen, big.mark=",")`

---
# Comparison of hospitals
Are penalized hospitals sufficiently similar to non-penalized hospitals?

--
<br>
<br>
Let's look at covariate balance using a love plot, part of the `library(cobalt)` package.

---
# Love plots without adjustment

```{r include=FALSE}
lp.vars <- final.hcris %>% 
  select(beds, mcaid_discharges, penalty, ip_charges, 
         mcare_discharges, tot_mcare_payment, price) %>%
  filter(complete.cases(.))
lp.covs <- lp.vars %>% select(-c("penalty","price"))
```

```{r cov-balance, eval=FALSE, warning=FALSE}
love.plot(bal.tab(lp.covs,treat=lp.vars$penalty), colors="black", shapes="circle", threshold=0.1) + 
  theme_bw() + theme(legend.position="none")
```

.plot-callout[
```{r cov-balance-callout, ref.label="cov-balance", fig.callout=TRUE, warning=FALSE}
```
]


---
# Love plots without adjustment

```{r cov-balance-output, ref.label="cov-balance", fig.callout=TRUE, warning=FALSE}
```

---
# Using matching to improve balance
Some things to think about:
- exact versus nearest neighbor
- with or without ties (and how to break ties)
- measure of distance

---
# 1. Exact Matching
```{r exact-matching1, echo=TRUE}
m.exact <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=lp.covs,
                           M=1,
                           exact=TRUE) #<<
print(m.exact)
```

---
# 1. Exact Matching (on a subset)
```{r exact-matching2, echo=TRUE}
lp.covs2 <- lp.covs %>% select(beds, mcaid_discharges)
m.exact <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=lp.covs2,
                           M=1,
                           exact=TRUE,
                           estimand="ATE") #<<
```

---
# 1. Exact Matching (on a subset)
```{r lp-exact, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.exact, covs = lp.covs2, treat = lp.vars$penalty),  
          threshold=0.1, 
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-exact-callout, ref.label="lp-exact", fig.callout=TRUE, warning=FALSE}
```
]


---
# 1. Exact Matching (on a subset)

```{r lp-exact-output, ref.label="lp-exact", fig.callout=TRUE, warning=FALSE}
```


---
# 2. Nearest neighbor matching (inverse variance)
```{r var-match1, echo=TRUE, warning=FALSE}
m.nn.var <- Matching::Match(Y=lp.vars$price,
                            Tr=lp.vars$penalty,
                            X=lp.covs,
                            M=4,  #<<
                            Weight=1,
                            estimand="ATE")

v.name=data.frame(new=c("Beds","Medicaid Discharges", "Inaptient Charges",
                   "Medicare Discharges", "Medicare Payments"))
```

---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-dist1, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.var, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-var-callout1, ref.label="lp-var-dist1", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-output1, ref.label="lp-var-dist1", fig.callout=TRUE, warning=FALSE}
```

---
# 2. Nearest neighbor matching (inverse variance)
```{r var-match2, echo=TRUE, warning=FALSE}
m.nn.var2 <- Matching::Match(Y=lp.vars$price,
                             Tr=lp.vars$penalty,
                             X=lp.covs,
                             M=1,   #<<
                             Weight=1,
                             estimand="ATE")
```

---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-dist2, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.var2, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-var-callout2, ref.label="lp-var-dist2", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (inverse variance)

```{r lp-var-output2, ref.label="lp-var-dist2", fig.callout=TRUE, warning=FALSE}
```


---
# 2. Nearest neighbor matching (Mahalanobis)
```{r md-match1, echo=TRUE, warning=FALSE}
m.nn.md <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=lp.covs,
                           M=1,
                           Weight=2,
                           estimand="ATE")                           
```

---
# 2. Nearest neighbor matching (Mahalanobis)

```{r lp-md-dist1, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.md, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-md-callout1, ref.label="lp-md-dist1", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (Mahalanobis)

```{r lp-md-output1, ref.label="lp-md-dist1", fig.callout=TRUE, warning=FALSE}
```

---
# 2. Nearest neighbor matching (propensity score)
```{r ps-match, echo=TRUE, warning=FALSE}
logit.model <- glm(penalty ~ beds + mcaid_discharges + ip_charges + mcare_discharges +
            tot_mcare_payment, family=binomial, data=lp.vars)
ps <- fitted(logit.model)
m.nn.ps <- Matching::Match(Y=lp.vars$price,
                           Tr=lp.vars$penalty,
                           X=ps,
                           M=1,
                           estimand="ATE")
```

---
# 2. Nearest neighbor matching (propensity score)

```{r lp-ps-match, eval=FALSE, warning=FALSE}
love.plot(bal.tab(m.nn.ps, covs = lp.covs, treat = lp.vars$penalty), 
          threshold=0.1, 
          var.names=v.name,
          grid=FALSE, sample.names=c("Unmatched", "Matched"),
          position="top", shapes=c("circle","triangle"),
          colors=c("black","blue")) + 
  theme_bw()
```

.plot-callout[
```{r lp-ps-callout, ref.label="lp-ps-match", fig.callout=TRUE, warning=FALSE}
```
]


---
# 2. Nearest neighbor matching (propensity score)

```{r lp-ps-output, ref.label="lp-ps-match", fig.callout=TRUE, warning=FALSE}
```

---
# 3. Weighting
```{r echo=F}
ggplot(lp.vars, aes(x=ps)) + geom_histogram() + 
  facet_wrap(~ penalty, ncol=1) +
  theme_bw()
```

---
# Results: Exact matching
```{r echo=FALSE}
summary(m.exact)
```


---
# Results: Nearest neighbor

- Inverse variance
```{r echo=FALSE}
summary(m.nn.var2)
```

---
# Results: Nearest neighbor

- Mahalanobis
```{r echo=FALSE}
summary(m.nn.md)
```

---
# Results: Nearest neighbor

- Propensity score
```{r echo=FALSE}
summary(m.nn.ps)
```


---
# Results: IPW weighting

```{r}
lp.vars <- lp.vars %>%
  mutate(ipw = case_when(
    penalty==1 ~ 1/ps,
    penalty==0 ~ 1/(1-ps),
    TRUE ~ NA_real_
  ))
mean.t1 <- lp.vars %>% filter(penalty==1) %>%
  select(price, ipw) %>% summarize(mean_p=weighted.mean(price,w=ipw))
mean.t0 <- lp.vars %>% filter(penalty==0) %>%
  select(price, ipw) %>% summarize(mean_p=weighted.mean(price,w=ipw))
mean.t1$mean_p - mean.t0$mean_p
```

---
# Results: IPW weighting with regression

```{r}
ipw.reg <- lm(price ~ penalty, data=lp.vars, weights=ipw)
summary(ipw.reg)
```

---
# Results: Regression

```{r}
reg1.dat <- lp.vars %>% filter(penalty==1, complete.cases(.))
reg1 <- lm(price ~ beds+ mcaid_discharges + ip_charges + mcare_discharges +
            tot_mcare_payment, data=reg1.dat)

reg0.dat <- lp.vars %>% filter(penalty==0, complete.cases(.))
reg0 <- lm(price ~ beds + mcaid_discharges + ip_charges + mcare_discharges +
            tot_mcare_payment, data=reg0.dat)
pred1 <- predict(reg1,new=lp.vars)
pred0 <- predict(reg0,new=lp.vars)
mean(pred1-pred0)
```

---
# Results: Regression in one step

```{r}
reg.dat <- lp.vars %>% ungroup() %>% filter(complete.cases(.)) %>%
  mutate(beds_diff = penalty*(beds - mean(beds)),
         mcaid_diff = penalty*(mcaid_discharges - mean(mcaid_discharges)),
         ip_diff = penalty*(ip_charges - mean(ip_charges)),
         mcare_diff = penalty*(mcare_discharges - mean(mcare_discharges)),
         mpay_diff = penalty*(tot_mcare_payment - mean(tot_mcare_payment)))
reg <- lm(price ~ penalty + beds + mcaid_discharges + ip_charges + mcare_discharges + tot_mcare_payment + 
            beds_diff + mcaid_diff + ip_diff + mcare_diff + mpay_diff,
          data=reg.dat)
```

---
# Results: Regression in one step

```{r echo=FALSE}
summary(reg)
```


---
# Summary of ATEs
1. Exact matching: `r round(m.exact$est[1],2)`
2. NN matching, inverse variance: `r round(m.nn.var2$est[1],2)`
3. NN matching, mahalanobis: `r round(m.nn.md$est[1],2)`
4. NN matching, pscore: `r round(m.nn.ps$est[1],2)`
5. Inverse pscore weighting: `r round(mean.t1$mean_p - mean.t0$mean_p,2)`
6. IPW regression: `r round(ipw.reg$coeff[2],2)`
7. Regression: `r round(mean(pred1-pred0),2)`
8. Regression 1-step: `r round(reg$coeff[2],2)`


---
# Summary of ATEs

Why such large differences between linear (unweighted) regression and other approaches?


--

Problem is due to common support. Without weighting, the treated group looks very different than the control group, and standard OLS (without weights) doesn't do anything to account for this.


<!-- New Section -->
---
class: inverse, center, middle
name: summary

# So what have we learned?

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>

---
# Key assumptions for causal inference
1. Selection on observables
2. Common support

--
<br>
<br>

These become more nuanced but the intuition is the same in almost all questions of causal inference.

---
# Causal effect assuming selection on observables
If we assume selection on observables holds, then we only need to condition on the relevant covariates to identify a causal effect. But we still need to ensure common support...<br>

--
<br>
1. Matching
2. Reweighting
3. Regression

